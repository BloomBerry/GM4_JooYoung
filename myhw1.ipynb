{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import torch\r\n",
    "from torchvision.utils import make_grid\r\n",
    "\r\n",
    "from loader.MNIST_dataset import MNIST_dataset\r\n",
    "from models.ae import AE\r\n",
    "from models.modules import FC_image\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# if you don't have gpu, \r\n",
    "# you can set device='cpu'\r\n",
    "device = f'cuda:0'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- In this exercise, you will study how to analyze MNIST image data that approximately lies on some low-dimensional manifold. \n",
    "- Here, we assume the manifold's dimension is 2 for visualization purpose. \n",
    "- For simplicity, we use MNIST image of digits 0, 1, 2, 3, 4"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "1. Load Dataset (MNIST digits 0, 1, 2, 3, 4)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- The script below automatically downloads the MNIST image data in \"datasets\" directory.\n",
    "- The image size is (1, 28, 28) which can be viewed as a data point living in $\\mathbb{R}^{784}$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_ds = MNIST_dataset(root='datasets', split='training', digits=[0, 1, 2, 3, 4])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_x = train_ds.data[:20]\r\n",
    "x_img = make_grid(test_x, nrow=10, value_range=(0, 1), pad_value=1)\r\n",
    "\r\n",
    "plt.figure(figsize=(10,10))\r\n",
    "plt.imshow(x_img.permute(1,2,0))\r\n",
    "plt.axis('off')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Load Pretrained Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- You should download the pre-trained model \"MNIST_digits_01234.pkl\" from [HERE](https://drive.google.com/file/d/1nUB6IcvMFxEguH42ZmvamU2oY1iYHQKS/view?usp=sharing) and put it in the \"pretrained/HW1/\" directory. \n",
    "- The torch.nn.Module class \"AE\" has the two main methods \"encode\" and \"decode\", each of which corresponds to the encoder and decoder."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "encoder = FC_image(in_chan=784, out_chan=2, l_hidden=[1024, 1024, ], activation=['elu', 'elu' ], out_activation='linear') \r\n",
    "decoder = FC_image(in_chan=2, out_chan=784, l_hidden=[1024, 1024, ], activation=['elu', 'elu' ], out_activation='sigmoid')\r\n",
    "\r\n",
    "pretrained_model = AE(encoder, decoder)\r\n",
    "pretrained_model.load_pretrained('pretrained/HW1/MNIST_digits_01234.pkl')\r\n",
    "pretrained_model.to(device);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Visualize Embeddings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Data points are mapped to the two-dimensioanl latent space (or coordinate space) by the encoder and visualized with label-coded colors."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "latent_embeddings = pretrained_model.encode(train_ds.data.to(device)).detach().cpu().numpy()\r\n",
    "\r\n",
    "z_scale = np.minimum(\r\n",
    "    np.max(latent_embeddings, axis=0), \r\n",
    "    np.min(latent_embeddings, axis=0)\r\n",
    ")\r\n",
    "labels = torch.unique(train_ds.targets)\r\n",
    "\r\n",
    "f = plt.figure(figsize=(7, 7))\r\n",
    "plt.title('Latent space embeddings')\r\n",
    "for label in labels:\r\n",
    "    classwise_le = latent_embeddings[train_ds.targets == label]\r\n",
    "    plt.scatter(\r\n",
    "        classwise_le[:200, 0], \r\n",
    "        classwise_le[:200, 1], \r\n",
    "        label=label.item(), s=10)\r\n",
    "plt.xlim(-3, 3)\r\n",
    "plt.ylim(-3, 3)\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Problem"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(a) Write the code for computing the Riemannian metric expressed in the latent space."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_Riemannian_metric(f, z, create_graph=False):\n",
    "    '''\n",
    "    f:      pretrained_model.decode\n",
    "    z:      torch.tensor whose size = (n, 2)\n",
    "    out:    torch.tensor whose size = (n, 2, 2)\n",
    "    '''\n",
    "    \n",
    "    ##############################################\n",
    "    ############### YOUR CODE HERE ###############\n",
    "    ##############################################\n",
    "    \n",
    "    out = None\n",
    "    return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Your function \"get_Riemannian_metric\" should pass the below test code."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_z = torch.randn(100, 2).to(device)\r\n",
    "\r\n",
    "G = get_Riemannian_metric(pretrained_model.decode, test_z)\r\n",
    "assert (G.size() == torch.Size([100, 2, 2]))\r\n",
    "\r\n",
    "rand_v = torch.randn(100, 2).to(device)\r\n",
    "assert torch.einsum('ni, nij, nj -> n', rand_v, G, rand_v).min().item() > 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- With the \"get_Riemannian_metric\" function that you wrote, the below code will visualize the Riemannian metrics evaluated at some randomly selected points as equidistant ellipses, where the equidistant ellipse is defined as follows: given a Riemannian metric $G(z)$ at $z$, the equidistant ellipse at $z$ is a set $\\{z' \\ | \\ (z'-z)^T G(z) (z'-z) = c\\}$ for some constant $c>0$.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from utils import visualize_Riemannian_metric_as_ellipses\r\n",
    "\r\n",
    "seed = 0\r\n",
    "torch.manual_seed(seed)\r\n",
    "torch.cuda.manual_seed(seed)\r\n",
    "    \r\n",
    "visualize_Riemannian_metric_as_ellipses(\r\n",
    "    train_ds, \r\n",
    "    pretrained_model, \r\n",
    "    get_Riemannian_metric, \r\n",
    "    device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q1) Can you interpret this result?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Now let's select class boundary points and visualize equidistant ellipses there."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bd_points = torch.tensor([\r\n",
    "    [-2, 0.3],\r\n",
    "    [-1.5, 0.1],\r\n",
    "    [-1, -0.1],\r\n",
    "    [-0.5, -0.7],\r\n",
    "    [-0.5, -1],\r\n",
    "    [-0.5, -2],\r\n",
    "    [0, -0.5],\r\n",
    "    [0.2, -0.6],\r\n",
    "    [1, -0.8],\r\n",
    "    [1.6, -0.7],\r\n",
    "    [2.1, -0.2],\r\n",
    "    [-0.2, -0.1],\r\n",
    "    [0.25, 0.25],\r\n",
    "    [0.5, 0.4],\r\n",
    "    [1, 0.8],\r\n",
    "    [-0.5, 1],\r\n",
    "    [-0.8, 1.4],\r\n",
    "    ], dtype=torch.float32).to(device)\r\n",
    "\r\n",
    "visualize_Riemannian_metric_as_ellipses(\r\n",
    "    train_ds, \r\n",
    "    pretrained_model, \r\n",
    "    get_Riemannian_metric, \r\n",
    "    device,\r\n",
    "    at=bd_points)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q2) In which directions are the ellipses longer? Can you interpret this result?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(b) Write the code for computing the legnth of a curve $z(t) \\in \\mathbb{R}^{2}$ for $t\\in[0,1]$ which corresponds to a curve on the two-dimensional MNIST data manifold, by using the \"get_Riemannian_metric\" function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def compute_length_of_curve(curve, pretrained_model, get_Riemannian_metric):\r\n",
    "    '''\r\n",
    "    curve:  torch.tensor whose size = (L, 2)\r\n",
    "    out:    torch.tensor whose size = (1)\r\n",
    "    '''\r\n",
    "    \r\n",
    "    ##############################################\r\n",
    "    ############### YOUR CODE HERE ###############\r\n",
    "    ##############################################\r\n",
    "    \r\n",
    "    out = None\r\n",
    "    return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Your function should pass the below test code."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x1 = test_x[0:1]\r\n",
    "x2 = test_x[1:2]\r\n",
    "\r\n",
    "z1 = pretrained_model.encode(x1.to(device))\r\n",
    "z2 = pretrained_model.encode(x2.to(device))\r\n",
    "\r\n",
    "list_len = []\r\n",
    "for num_discretization in [100, 1000]:\r\n",
    "    z_curve = torch.cat([z1 + (z2 - z1) * t/(num_discretization-1) for t in range(num_discretization)], dim=0)\r\n",
    "    L = compute_length_of_curve(z_curve, pretrained_model, get_Riemannian_metric).item()\r\n",
    "    list_len.append(L)\r\n",
    "assert ((list_len[0] - list_len[1])/list_len[0] < 0.1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Now, you will compare the lengths of two curves whose lengths are same in the latent space.\n",
    "- Below, the red and green squares correspond to digit 2 images and the blue square corresponds to digit 4 image."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "z1 = torch.tensor([[1, -1.2]], dtype=torch.float32) # digit 2 (red)\r\n",
    "z2 = torch.tensor([[0, -1.2]], dtype=torch.float32) # digit 2 (green)\r\n",
    "z3 = torch.tensor([[1, -0.2]], dtype=torch.float32) # digit 4 (blue)\r\n",
    "\r\n",
    "latent_embeddings = pretrained_model.encode(\r\n",
    "    train_ds.data.to(device)\r\n",
    "    ).detach().cpu().numpy()\r\n",
    "\r\n",
    "z_scale = np.minimum(\r\n",
    "    np.max(latent_embeddings, axis=0), \r\n",
    "    np.min(latent_embeddings, axis=0)\r\n",
    ")\r\n",
    "labels = torch.unique(train_ds.targets)\r\n",
    "\r\n",
    "f = plt.figure(figsize=(7, 7))\r\n",
    "plt.title('Latent space embeddings')\r\n",
    "for label in labels:\r\n",
    "    classwise_le = latent_embeddings[train_ds.targets == label]\r\n",
    "    plt.scatter(\r\n",
    "        classwise_le[:200, 0], \r\n",
    "        classwise_le[:200, 1], \r\n",
    "        label=label.item(), s=5)\r\n",
    "\r\n",
    "plt.scatter(z1[0, 0], z1[0, 1], c='tab:red', marker='s', s=100)\r\n",
    "plt.scatter(z2[0, 0], z2[0, 1], c='tab:green', marker='s', s=100)\r\n",
    "plt.scatter(z3[0, 0], z3[0, 1], c='tab:blue', marker='s', s=100)\r\n",
    "\r\n",
    "plt.plot((z1[0, 0], z2[0, 0]), (z1[0, 1], z2[0, 1]), c='k')\r\n",
    "plt.plot((z1[0, 0], z3[0, 0]), (z1[0, 1], z3[0, 1]), c='k')\r\n",
    "\r\n",
    "plt.xlim(-3, 3)\r\n",
    "plt.ylim(-3, 3)\r\n",
    "\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x1 = pretrained_model.decode(z1.to(device)) # red\n",
    "x2 = pretrained_model.decode(z2.to(device)) # green \n",
    "x3 = pretrained_model.decode(z3.to(device)) # blue\n",
    "\n",
    "x_img = make_grid(\n",
    "    torch.cat([x1, x2, x3], dim=0).detach().cpu(), \n",
    "    nrow=3, value_range=(0, 1), pad_value=1)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(x_img.permute(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Compute the lengths of two curves, red2green and red2blue straight lines, by using the \"compute_length_of_curve\" function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_discretization = 100\n",
    "z12_linear_curve = torch.cat([z1.to(device) + (z2.to(device) - z1.to(device)) * t/(num_discretization-1) for t in range(num_discretization)], dim=0)\n",
    "z13_linear_curve = torch.cat([z1.to(device) + (z3.to(device) - z1.to(device)) * t/(num_discretization-1) for t in range(num_discretization)], dim=0)\n",
    "\n",
    "L12 = compute_length_of_curve(\n",
    "    z12_linear_curve\n",
    "    , pretrained_model, get_Riemannian_metric)\n",
    "L13 = compute_length_of_curve(\n",
    "    z13_linear_curve\n",
    "    , pretrained_model, get_Riemannian_metric)\n",
    "L12, L13"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q3) Which curve is longer? Why?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(c) Write the code for finding the geodesic curve that connects two points $z_1, z_2 \\in \\mathbb{R}^2$ by using your \"get_Riemannian_metric\" function (you may want to use some python library for optimization, e.g., scipy.optimize.minimize, and use one of the gradient-based methods for fast optimization)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def compute_geodesic(z1, z2, pretrained_model, get_Riemannian_metric, num_discretization=100):\n",
    "    '''\n",
    "    z1 : torch.tensor whose size = (1, 2)\n",
    "    z1 : torch.tensor whose size = (1, 2)\n",
    "    out: torch.tensor whose size = (num_discretization, 2)\n",
    "    '''\n",
    "    \n",
    "    ##############################################\n",
    "    ############### YOUR CODE HERE ###############\n",
    "    ##############################################\n",
    "    \n",
    "    out = None\n",
    "    return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Your code should pass the below test code."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "z1 = torch.tensor([[-1, 1]], dtype=torch.float32) \n",
    "z2 = torch.tensor([[0.6, -1.2]], dtype=torch.float32) \n",
    "\n",
    "num_discretization = 100\n",
    "z12_geodesic_curve = compute_geodesic(\n",
    "    z1.to(device), \n",
    "    z2.to(device), \n",
    "    pretrained_model, \n",
    "    get_Riemannian_metric, \n",
    "    num_discretization=num_discretization\n",
    ")\n",
    "assert z12_geodesic_curve.size() == torch.Size([num_discretization, 2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Compute the lengths of the geodesic curve (i.e., geodesic distances)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "L12 = compute_length_of_curve(\n",
    "    z12_geodesic_curve, pretrained_model, get_Riemannian_metric)\n",
    "L12"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Let's compare the geodesic and linear interpolation results.\n",
    "- The gray line is the linear interpolation in the latent space and the pink line is the geodesic interpolation. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "z12_linear_curve = torch.cat([z1.to(device) + (z2.to(device) - z1.to(device)) * t/(num_discretization-1) for t in range(num_discretization)], dim=0)\n",
    "\n",
    "latent_embeddings = pretrained_model.encode(\n",
    "    train_ds.data.to(device)\n",
    "    ).detach().cpu().numpy()\n",
    "\n",
    "z_scale = np.minimum(\n",
    "    np.max(latent_embeddings, axis=0), \n",
    "    np.min(latent_embeddings, axis=0)\n",
    ")\n",
    "labels = torch.unique(train_ds.targets)\n",
    "\n",
    "f = plt.figure(figsize=(7, 7))\n",
    "plt.title('Latent space embeddings')\n",
    "for label in labels:\n",
    "    classwise_le = latent_embeddings[train_ds.targets == label]\n",
    "    plt.scatter(\n",
    "        classwise_le[:200, 0], \n",
    "        classwise_le[:200, 1], \n",
    "        label=label.item(), s=5)\n",
    "\n",
    "plt.scatter(z1[0, 0], z1[0, 1], c='tab:red', marker='s')\n",
    "plt.scatter(z2[0, 0], z2[0, 1], c='tab:green', marker='s')\n",
    "\n",
    "plt.scatter(z12_linear_curve[:, 0].detach().cpu(), z12_linear_curve[:, 1].detach().cpu(), s=10, c='tab:gray')\n",
    "plt.scatter(z12_geodesic_curve[:, 0].detach().cpu(), z12_geodesic_curve[:, 1].detach().cpu(), s=10, c='tab:pink')\n",
    "\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Below visualizes the corresponding sequences of images."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x12_linear_curve = pretrained_model.decode(z12_linear_curve)\n",
    "x12_geodesic_curve = pretrained_model.decode(z12_geodesic_curve)\n",
    "\n",
    "x_img = make_grid(\n",
    "    torch.cat([\n",
    "        x12_linear_curve[0:-1:5], \n",
    "        x12_geodesic_curve[0:-1:5]], dim=0).detach().cpu(), \n",
    "    nrow=20, value_range=(0, 1), pad_value=1)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(x_img.permute(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q4) How are they different? Why?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Lastly, you will implement a clustering algorithm by using the geodesic distances and compare it with a usal Euclidean distance-based clustering algorithm in the latent sapce.\n",
    "- We will use the SpectralClustering algorithm and only consider a subset of digit 2 and 4 images for simplicity. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "latent_embeddings = pretrained_model.encode(\n",
    "    train_ds.data.to(device)\n",
    "    ).detach().cpu()\n",
    "data = []\n",
    "targets = []\n",
    "labels = [2, 4]\n",
    "\n",
    "num_for_each_class = 20\n",
    "for label in labels:\n",
    "    classwise_le = latent_embeddings[train_ds.targets == label]\n",
    "    data.append(classwise_le[:num_for_each_class])\n",
    "    targets.append(train_ds.targets[train_ds.targets == label][:num_for_each_class])\n",
    "data = torch.cat(data, dim=0)\n",
    "targets = torch.cat(targets, dim=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "## Euclidean clustering\n",
    "SC = SpectralClustering(n_clusters=2)\n",
    "SC.fit(data)\n",
    "Euclidean_est = torch.tensor(SC.labels_)\n",
    "\n",
    "## Geodesic clustering\n",
    "num_data = len(data)\n",
    "tau = 10000\n",
    "affinity_matrix = np.eye(num_data)\n",
    "for i in range(num_data):\n",
    "    for j in range(i+1, num_data):\n",
    "        z1 = data[i:i+1]\n",
    "        z2 = data[j:j+1]\n",
    "        z12_geodesic_curve = compute_geodesic(\n",
    "            z1.to(device), \n",
    "            z2.to(device), \n",
    "            pretrained_model, \n",
    "            get_Riemannian_metric, \n",
    "            num_discretization=100)\n",
    "        dist = compute_length_of_curve(\n",
    "            z12_geodesic_curve, pretrained_model, get_Riemannian_metric)\n",
    "        affinity_matrix[i, j] = 2 * np.exp(-dist.item()**2/tau) \n",
    "        print(f'{i}-{j} done') \n",
    "\n",
    "affinity_matrix = (affinity_matrix + affinity_matrix.transpose())/2\n",
    "SC = SpectralClustering(n_clusters=2, affinity='precomputed')\n",
    "SC.fit(affinity_matrix)\n",
    "Geodesic_est = torch.tensor(SC.labels_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## plots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "for label in labels:\n",
    "    classwise_le = data[targets == label]\n",
    "    axes[0].scatter(\n",
    "        classwise_le[:, 0], \n",
    "        classwise_le[:, 1], \n",
    "        label=label, s=20)\n",
    "axes[0].set_title('ground truth class')\n",
    "\n",
    "for label in [0, 1]:\n",
    "    classwise_le = data[Euclidean_est == label]\n",
    "    axes[1].scatter(\n",
    "        classwise_le[:, 0], \n",
    "        classwise_le[:, 1], \n",
    "        label=label, s=20)\n",
    "axes[1].set_title('Eucldiean clustering result')\n",
    "\n",
    "for label in [0, 1]:\n",
    "    classwise_le = data[Geodesic_est == label]\n",
    "    axes[2].scatter(\n",
    "        classwise_le[:, 0], \n",
    "        classwise_le[:, 1], \n",
    "        label=label, s=20)\n",
    "axes[2].set_title('Geodesic clustering result')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q5) Compare the results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- To see more experiemnt results by using the latent space Riemannian metric, e.g., clustering with geodesic distances, chcek out the paper [\"Latent Space Oddity: on the Curvature of Deep Generative Models\"](https://arxiv.org/abs/1710.11379)."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('HarmonicAE')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77e9a852e0c276bc2d2fb155a244ad287beb68d9483b4af08f89864de2098ab0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}